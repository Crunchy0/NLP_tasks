{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4e9673",
   "metadata": {},
   "source": [
    "# Задание 3: автореферирование текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e4985",
   "metadata": {},
   "source": [
    "## 1) Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15b9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "from sumy.evaluation.rouge import rouge_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2570c",
   "metadata": {},
   "source": [
    "## 2) Загрузка данных и функция обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5878eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, summarizer):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer('russian'))\n",
    "    sentences_orig = parser.document.sentences\n",
    "    \n",
    "    summary = summarizer(parser.document, 2)\n",
    "    result = '\\n\\n'.join([str(sent) for sent in summary])[:300]\n",
    "    \n",
    "    parser = PlaintextParser.from_string(result, Tokenizer('russian'))\n",
    "    sentences_result = parser.document.sentences\n",
    "    \n",
    "    score = rouge_2(sentences_result, sentences_orig)\n",
    "    \n",
    "    return (result, score)\n",
    "\n",
    "with open('example_texts.json', 'r', encoding='utf-8') as file:\n",
    "    texts = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b754acd",
   "metadata": {},
   "source": [
    "## 3) LexRank\n",
    "\n",
    "Данный алгоритм представляет собой модификацию популярного TextRank. В его основе так же лежит <a href=\"https://snap.stanford.edu/class/cs224w-readings/Brin98Anatomy.pdf\">PageRank</a>, который в контексте автореферирования применянется для ранжирования текстов.\n",
    "\n",
    "В отличие от TextRank, LexRank использует другую метрику схожести:\n",
    "\n",
    "$\\large sim_{ij} = \\frac{\\sum_{w\\in\\{S_i\\cup S_j\\}} {tf}_w^i * {tf}_w^j * ({idf}_w)^2}{\\sqrt{\\sum_{w\\in S_i} ({tf}_w^i * {idf}_w)^2} * \\sqrt{\\sum_{w\\in S_j} ({tf}_w^j * {idf}_w)^2}}$\n",
    "\n",
    "$\\large {tf}_w^i = \\frac{|\\{w_k \\mid (w_k \\in S_i) \\wedge (w_k = w)\\}|}{|S_i|}$\n",
    "\n",
    "$\\large {idf}_w = log(\\frac{|\\mathbb{S}|}{|\\{S_i \\mid w \\in S_i\\}|})$\n",
    "\n",
    "Здесь $\\mathbb{S}$ - множество всех предложений, $S_i$ - набор слов $i$-го предложения, $w$ - токены в предложении. Такая метрика позволяет больше учитывать редкие термины вместо того чтобы отдавать предпочтение часто употребляемым словам.\n",
    "\n",
    "К тому же, веса ребрер между предложениями, имеющими низкую схожесть, обнуляются. Для этого задается пороговое значение $t$ (в реализации <b>sumy</b> это $t=0.1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8466a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_summaries = []\n",
    "\n",
    "LexRankSummarizer.threshold = 0.05 # 0.1\n",
    "LexRankSummarizer.epsilon = 0.05 # 0.1\n",
    "\n",
    "for text in texts:    \n",
    "    lr_summaries.append(summarize(text, LexRankSummarizer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fb9303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary #1:\n",
      "Увидеть мысль\n",
      "\n",
      "За последние несколько лет нейрофизиология сделала большой шаг вперед в понимании работы человеческого мозга .\n",
      "ROUGE-2: 0.11666666666666667\n",
      "\n",
      "Summary #2:\n",
      "Карбофос ( O , O - Диметил - S - ( 1,2 - дикарбэтоксиэтил ) дитиофосфат , малатион ) — фосфорорганическое соединение , инсектицид широкого спектра действия , акарицид .\n",
      "\n",
      "Механизм действия\n",
      "ROUGE-2: 0.17045454545454544\n",
      "\n",
      "Summary #3:\n",
      "Киев идет на уступки : Яценюк передает власть на местах Советам\n",
      "\n",
      "Центральная власть готова не просто к диалогу с регионами , а к выполнению законных требований и желаний каждого жителя нашей страны , и мы в рамках изменений Конституции будем в состоянии ответить на все чаяния , на каждую специфику к\n",
      "ROUGE-2: 0.20657276995305165\n",
      "\n",
      "Summary #4:\n",
      "Но дело в том , что , во-первых , срок оплаты за июль ― 10 августа , так что я ещё не платила за июль , и долг не мог образоваться физически !\n",
      "\n",
      "Немцов , который недавно не смог стать мэром не то что Москвы , а даже маленьких Сочей ( о которых бы никто и не вспомнил , если б не грядущая Олимпиада там\n",
      "ROUGE-2: 0.025853154084798345\n",
      "\n",
      "Summary #5:\n",
      "Потому что все пишут обычно на двойном тетрадном листочке ( когда его подшиваешь в дело , он оказывается длиннее листа А4 , и край приходится подгибать ) , и ( иногда ) -- ТАКОЕ ( как , например , пенсионерка Тютюник : раз , два ) .\n",
      "\n",
      "И еще , если ходатайство из СИЗО , там в конце обычно приписка : &\n",
      "ROUGE-2: 0.21390374331550802\n"
     ]
    }
   ],
   "source": [
    "for num, res in enumerate(lr_summaries):\n",
    "    summ, score = res\n",
    "    print('\\n', end=f'Summary #{num + 1}:\\n')\n",
    "    print(summ)\n",
    "    print(f'ROUGE-2: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cc244",
   "metadata": {},
   "source": [
    "## 4) Запись результатов в JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aace24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_obj = [summ for summ, score in lr_summaries]\n",
    "ind = '\\t'\n",
    "sep = (',', ' : ')\n",
    "\n",
    "with open('output_texts.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(output_obj, file, ensure_ascii=False, indent=ind, separators=sep)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
